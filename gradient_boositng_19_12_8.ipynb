{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2600, 501)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('medilon.csv')\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Class'], axis = 1)\n",
    "y = df['Class']\n",
    "type(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aanup\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = RandomForestClassifier(random_state = 0, n_jobs = -1)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    " \n",
    "X.head()\n",
    "# Create a random forest classifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, random_state = 0)\n",
    " \n",
    "feat_labels = X.columns.values\n",
    "# Fitting the classifier\n",
    "gbc.fit(X, y)\n",
    "\n",
    "# for feature in zip(feat_labels, rfc.feature_importances_):\n",
    "#     print(feature) \n",
    "\n",
    "importances = gbc.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "std = np.std([tree[0].feature_importances_ for tree in gbc.estimators_],\n",
    "                 axis=0)\n",
    "zipped = zip(feat_labels, importances)\n",
    "# zipped.sort(key = lambda t: t[1])\n",
    "\n",
    "sorted_list = sorted(zipped, key=lambda x: x[1])\n",
    "gini_values = sorted_list[::-1]\n",
    "\n",
    "a = gini_values[:13]\n",
    "# print(type(sorted_list))\n",
    "# b = []\n",
    "# for i in range(len(gini_values)):\n",
    "#     if a[i][0]\n",
    "top_n = 30\n",
    "indices = indices[0:top_n]\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.title(\"Feature importances top %d\" % top_n)\n",
    "plt.bar(range(top_n), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(top_n), indices)\n",
    "plt.xlim([-1,top_n])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[338, 475, 48, 153, 318, 378, 28, 105, 442, 128, 281, 451, 4]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = []\n",
    "for i in range(len(a)):\n",
    "    b.append(a[i][0])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newdf = X.iloc[:, b[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>338</th>\n",
       "      <th>475</th>\n",
       "      <th>48</th>\n",
       "      <th>153</th>\n",
       "      <th>318</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.312752</td>\n",
       "      <td>-1.150611</td>\n",
       "      <td>-1.062896</td>\n",
       "      <td>0.753090</td>\n",
       "      <td>-1.556575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.276465</td>\n",
       "      <td>0.849855</td>\n",
       "      <td>0.324217</td>\n",
       "      <td>-0.995529</td>\n",
       "      <td>-0.359177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.728733</td>\n",
       "      <td>-0.434228</td>\n",
       "      <td>-0.592688</td>\n",
       "      <td>0.855348</td>\n",
       "      <td>0.446345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.288328</td>\n",
       "      <td>1.566239</td>\n",
       "      <td>1.029529</td>\n",
       "      <td>0.916703</td>\n",
       "      <td>-0.598657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.079571</td>\n",
       "      <td>0.998539</td>\n",
       "      <td>-1.321510</td>\n",
       "      <td>-0.545592</td>\n",
       "      <td>-0.511573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>-0.676919</td>\n",
       "      <td>0.606555</td>\n",
       "      <td>-0.663219</td>\n",
       "      <td>0.926929</td>\n",
       "      <td>0.533428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>-0.252041</td>\n",
       "      <td>0.214572</td>\n",
       "      <td>-1.227468</td>\n",
       "      <td>0.640606</td>\n",
       "      <td>-1.142928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>-0.500750</td>\n",
       "      <td>0.376772</td>\n",
       "      <td>0.488790</td>\n",
       "      <td>-0.218365</td>\n",
       "      <td>1.709055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>-0.842725</td>\n",
       "      <td>0.471389</td>\n",
       "      <td>0.817935</td>\n",
       "      <td>0.671283</td>\n",
       "      <td>-0.968762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>-0.594016</td>\n",
       "      <td>-1.191161</td>\n",
       "      <td>-1.109916</td>\n",
       "      <td>1.284833</td>\n",
       "      <td>0.664053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2600 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           338       475       48        153       318\n",
       "0     1.312752 -1.150611 -1.062896  0.753090 -1.556575\n",
       "1     0.276465  0.849855  0.324217 -0.995529 -0.359177\n",
       "2    -0.728733 -0.434228 -0.592688  0.855348  0.446345\n",
       "3    -1.288328  1.566239  1.029529  0.916703 -0.598657\n",
       "4     0.079571  0.998539 -1.321510 -0.545592 -0.511573\n",
       "...        ...       ...       ...       ...       ...\n",
       "2595 -0.676919  0.606555 -0.663219  0.926929  0.533428\n",
       "2596 -0.252041  0.214572 -1.227468  0.640606 -1.142928\n",
       "2597 -0.500750  0.376772  0.488790 -0.218365  1.709055\n",
       "2598 -0.842725  0.471389  0.817935  0.671283 -0.968762\n",
       "2599 -0.594016 -1.191161 -1.109916  1.284833  0.664053\n",
       "\n",
       "[2600 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rf_train, Rf_test, y_train, y_test = train_test_split(Newdf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318, 0.7557692307692307)\n",
      "(378, 0.7903846153846154)\n",
      "(28, 0.8134615384615385)\n",
      "(105, 0.7903846153846154)\n",
      "(442, 0.8096153846153846)\n",
      "(128, 0.8307692307692308)\n",
      "(281, 0.8307692307692308)\n",
      "(451, 0.8076923076923077)\n",
      "(4, 0.8288461538461539)\n"
     ]
    }
   ],
   "source": [
    "'''list to hold accuracy, index and those index that need to be removed'''\n",
    "accuracy = []\n",
    "index = []\n",
    "remove_index = []\n",
    "# for i in range(15):\n",
    "#     Newdf = X.iloc[:, b[:4+i]]\n",
    "#     index.append(4+i)\n",
    "#     Rf_train, Rf_test, y_train, y_test = train_test_split(Newdf, y, test_size=0.2, random_state=42)\n",
    "#     rfc = DecisionTreeClassifier(random_state = 0)\n",
    "#     rfc.fit(Rf_train, y_train)\n",
    "#     rfc_predict = rfc.predict(Rf_test)\n",
    "#     accuracy.append(accuracy_score(y_test, rfc_predict))\n",
    "#     print(\"Accuracy: \", accuracy_score(y_test, rfc_predict))\n",
    "\n",
    "'''We decided to choose first 4 columns which have highest gini index and compare wrt them\n",
    "by adding other columns itteratively''' \n",
    "\n",
    "\n",
    "highest_accuracy = 0\n",
    "for i in range(9):\n",
    "    Newdf = X.iloc[:, b[:4+i]]\n",
    "    index.append(b[4+i])\n",
    "    \n",
    "    Rf_train, Rf_test, y_train, y_test = train_test_split(Newdf, y, test_size=0.2, random_state=42)\n",
    "    rfc = DecisionTreeClassifier(random_state = 0)\n",
    "    rfc.fit(Rf_train, y_train)\n",
    "    rfc_predict = rfc.predict(Rf_test)\n",
    "    accuracy.append(accuracy_score(y_test, rfc_predict))\n",
    "    if (accuracy[i] - accuracy[i-1]) < 0 or (accuracy[i] - highest_accuracy) < 0:\n",
    "        if accuracy[i-1] - highest_accuracy >0:\n",
    "            highest_accuracy = accuracy[i-1]\n",
    "        remove_index.append(b[4+i])\n",
    "#     print(\"Accuracy: \", accuracy_score(y_test, rfc_predict))\n",
    "    \n",
    "for indexed in zip(index, accuracy):\n",
    "    print(indexed)\n",
    "# print(index)  \n",
    "# print(remove_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[318, 378, 28, 128, 281, 105, 338, 475, 48, 153]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Uncomment the following two lines if you are running this code for first time\n",
    "commented out for testing purpose'''\n",
    "dtselected_index = [i for i in index  + remove_index if i not in index or i not in remove_index]\n",
    "dtselected_index.append(remove_index[0])\n",
    "'''These are the columns chosen out of the 20(which had highest gini index)\n",
    "We removed those columns whose addition caused decrease in accuracy since\n",
    "they add no value to the predictive capability of model rather decrease the accuracy'''\n",
    "\n",
    "for i in range(4):\n",
    "    dtselected_index.append(b[i])\n",
    "\n",
    "dtselected_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7423076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aanup\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\aanup\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:576: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "'''This was for testing'''\n",
    "iloceddf  = X.iloc[:, b[:4]]\n",
    "iloceddf.loc[:, b[10]] = X.iloc[:, b[10]]\n",
    "\n",
    "Rf_train, Rf_test, y_train, y_test = train_test_split(iloceddf, y, test_size=0.2, random_state=42)\n",
    "rfc = DecisionTreeClassifier(random_state = 0)\n",
    "rfc.fit(Rf_train, y_train)\n",
    "rfc_predict = rfc.predict(Rf_test)\n",
    "# accuracy.append(accuracy_score(y_test, rfc_predict))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, rfc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8096153846153846\n"
     ]
    }
   ],
   "source": [
    "chosendf = X.iloc[:, dtselected_index]\n",
    "\n",
    "Rf_train, Rf_test, y_train, y_test = train_test_split(chosendf, y, test_size=0.2, random_state=42)\n",
    "rfc = DecisionTreeClassifier(random_state = 0)\n",
    "rfc.fit(Rf_train, y_train)\n",
    "rfc_predict = rfc.predict(Rf_test)\n",
    "# accuracy.append(accuracy_score(y_test, rfc_predict))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, rfc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ok the accuracy has decreased---------Conclusion\\nso we can't remove any columns that contributed to the highest accuracy\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Ok the accuracy has decreased---------Conclusion\n",
    "so we can't remove any columns that contributed to the highest accuracy'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8307692307692308\n"
     ]
    }
   ],
   "source": [
    "'''We procced to take all those columns i.e 10 columns'''\n",
    "\n",
    "testdf = X.iloc[:, b[:10]]\n",
    "\n",
    "Rf_train, Rf_test, y_train, y_test = train_test_split(testdf, y, test_size=0.2, random_state=42)\n",
    "rfc = DecisionTreeClassifier(random_state = 0)\n",
    "rfc.fit(Rf_train, y_train)\n",
    "rfc_predict = rfc.predict(Rf_test)\n",
    "# accuracy.append(accuracy_score(y_test, rfc_predict))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, rfc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n",
      "(318, 0.8173076923076923)\n",
      "(378, 0.85)\n",
      "(28, 0.85)\n",
      "(105, 0.8461538461538461)\n",
      "(442, 0.875)\n",
      "(128, 0.8807692307692307)\n",
      "(281, 0.8846153846153846)\n"
     ]
    }
   ],
   "source": [
    "'''Lets try with Random Forest Classifier'''\n",
    "\n",
    "'''list to hold accuracy, index and those index that need to be removed'''\n",
    "accuracy = []\n",
    "index = []\n",
    "remove_index = []\n",
    "\n",
    "'''We decided to choose first 4 columns which have highest gini index and compare wrt them\n",
    "by adding other columns itteratively''' \n",
    "\n",
    "\n",
    "highest_accuracy = 0\n",
    "for i in range(7):\n",
    "    Newdf = X.iloc[:, b[:4+i]]\n",
    "    index.append(b[4+i])\n",
    "    \n",
    "    Rf_train, Rf_test, y_train, y_test = train_test_split(Newdf, y, test_size=0.2, random_state=42)\n",
    "    rfc = RandomForestClassifier(n_estimators=100, random_state = 0)\n",
    "    rfc.fit(Rf_train, y_train)\n",
    "    rfc_predict = rfc.predict(Rf_test)\n",
    "    accuracy.append(accuracy_score(y_test, rfc_predict))\n",
    "    if (accuracy[i] - accuracy[i-1]) < 0 or (accuracy[i] - highest_accuracy) <= 0:\n",
    "        if accuracy[i-1] - highest_accuracy >0:\n",
    "            highest_accuracy = accuracy[i-1]\n",
    "            print(highest_accuracy)\n",
    "        remove_index.append(b[4+i])\n",
    "#     if (accuracy[i] - highest_accuracy) >0:\n",
    "#         highest_accuracy = accuracy[i]\n",
    "\n",
    "for indexed in zip(index, accuracy):\n",
    "    print(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[318, 378, 28, 105, 442, 128, 281]\n",
      "[105]\n"
     ]
    }
   ],
   "source": [
    "print(index)\n",
    "print(remove_index)\n",
    "\n",
    "indexdf = X.iloc[:, index]\n",
    "\n",
    "Rfindex_train, Rfindex_test, y_train, y_test = train_test_split(indexdf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[318, 378, 28, 442, 128, 281, 105, 338, 475, 48, 153]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Uncomment the following two lines if you are running this code for first time\n",
    "commented out for testing purpose'''\n",
    "rfselected_index = []\n",
    "rfselected_index = [i for i in index  + remove_index if i not in index or i not in remove_index]\n",
    "rfselected_index.append(remove_index[0])\n",
    "'''These are the columns chosen out of the 20(which had highest gini index)\n",
    "We removed those columns whose addition caused decrease in accuracy since\n",
    "they add no value to the predictive capability of model rather decrease the accuracy'''\n",
    "\n",
    "for i in range(4):\n",
    "    rfselected_index.append(b[i])\n",
    "\n",
    "rfselected_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8903846153846153\n"
     ]
    }
   ],
   "source": [
    "chosendf = X.iloc[:, rfselected_index]\n",
    "\n",
    "Rf_train, Rf_test, y_train, y_test = train_test_split(chosendf, y, test_size=0.2, random_state=42)\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state = 0)\n",
    "rfc.fit(Rf_train, y_train)\n",
    "rfc_predict = rfc.predict(Rf_test)\n",
    "# accuracy.append(accuracy_score(y_test, rfc_predict))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, rfc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We could try out every combination'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''We succesfully reduced our 7 columns from our 20 columns set'''\n",
    "\n",
    "#TODO\n",
    "'''We could try out every combination''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                 class_weight=None,\n",
       "                                                 criterion='gini',\n",
       "                                                 max_depth=None,\n",
       "                                                 max_features='auto',\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100, n_jobs=None,\n",
       "                                                 oob_score=False,\n",
       "                                                 random_state=0, verbose=0,\n",
       "                                                 warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_ = SelectFromModel(estimator=RandomForestClassifier(n_estimators=100, random_state = 0))\n",
    "sel_.fit(Rfindex_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318, False)\n",
      "(378, True)\n",
      "(28, False)\n",
      "(105, False)\n",
      "(442, True)\n",
      "(128, False)\n",
      "(281, True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[378, 442, 281]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feat = sel_.get_support()\n",
    "selected_index_ = []\n",
    "for feat in(zip(index, selected_feat)):\n",
    "    print(feat)\n",
    "selected_index_ = [x for x, y in zip(index, selected_feat) if y == True]\n",
    "selected_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 500\n",
      "Selected features: 3\n"
     ]
    }
   ],
   "source": [
    "selected_feat = Rfindex_train.columns[(sel_.get_support())] #Make a list of with selected features\n",
    "print('Total features: {}'.format((X_train.shape[1])))\n",
    "print('Selected features: {}'.format(len(selected_feat)))\n",
    "# print('Features with coefficients shrunk to 0: {}'.format(\n",
    "#       np.sum(sel_.estimator_.coef_ == 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6788461538461539\n"
     ]
    }
   ],
   "source": [
    "Rf_selected = X.iloc[:, selected_feat]\n",
    "Rf_train, Rf_test, y_train, y_test = train_test_split(Rf_selected, y, test_size=0.2, random_state=42)\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state = 0)\n",
    "rfc.fit(Rf_train, y_train)\n",
    "rfc_predict = rfc.predict(Rf_test)\n",
    "# accuracy.append(accuracy_score(y_test, rfc_predict))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, rfc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8615384615384616\n",
      "0.9115384615384615\n",
      "(318, 0.8057692307692308)\n",
      "(378, 0.8615384615384616)\n",
      "(28, 0.8576923076923076)\n",
      "(105, 0.8634615384615385)\n",
      "(442, 0.8961538461538462)\n",
      "(128, 0.9115384615384615)\n",
      "(281, 0.9115384615384615)\n",
      "(451, 0.9019230769230769)\n",
      "(4, 0.8942307692307693)\n"
     ]
    }
   ],
   "source": [
    "'''Lets try with Extra Tree Classifier'''\n",
    "\n",
    "'''list to hold accuracy, index and those index that need to be removed'''\n",
    "accuracy = []\n",
    "index = []\n",
    "remove_index = []\n",
    "\n",
    "'''We decided to choose first 4 columns which have highest gini index and compare wrt them\n",
    "by adding other columns itteratively''' \n",
    "\n",
    "\n",
    "highest_accuracy = 0\n",
    "for i in range(9):\n",
    "    Newdf = X.iloc[:, b[:4+i]]\n",
    "    index.append(b[4+i])\n",
    "    \n",
    "    Rf_train, Rf_test, y_train, y_test = train_test_split(Newdf, y, test_size=0.2, random_state=42)\n",
    "    etc = ExtraTreesClassifier(n_estimators=100, random_state = 0)\n",
    "    etc.fit(Rf_train, y_train)\n",
    "    etc_predict = etc.predict(Rf_test)\n",
    "    accuracy.append(accuracy_score(y_test, etc_predict))\n",
    "    if (accuracy[i] - accuracy[i-1]) < 0 or (accuracy[i] - highest_accuracy) <= 0:\n",
    "        if accuracy[i-1] - highest_accuracy >0:\n",
    "            highest_accuracy = accuracy[i-1]\n",
    "            print(highest_accuracy)\n",
    "        remove_index.append(b[4+i])\n",
    "#     if (accuracy[i] - highest_accuracy) >0:\n",
    "#         highest_accuracy = accuracy[i]\n",
    "\n",
    "for indexed in zip(index, accuracy):\n",
    "    print(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[318, 378, 28, 105, 442, 128, 281, 451, 4]\n",
      "[28, 451, 4]\n"
     ]
    }
   ],
   "source": [
    "print(index)\n",
    "print(remove_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[318, 378, 105, 442, 128, 281, 28, 338, 475, 48, 153]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Uncomment the following two lines if you are running this code for first time\n",
    "commented out for testing purpose'''\n",
    "etselected_index = []\n",
    "etselected_index = [i for i in index  + remove_index if i not in index or i not in remove_index]\n",
    "etselected_index.append(remove_index[0])\n",
    "'''These are the columns chosen out of the 20(which had highest gini index)\n",
    "We removed those columns whose addition caused decrease in accuracy since\n",
    "they add no value to the predictive capability of model rather decrease the accuracy'''\n",
    "\n",
    "for i in range(4):\n",
    "    etselected_index.append(b[i])\n",
    "\n",
    "etselected_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9019230769230769\n"
     ]
    }
   ],
   "source": [
    "chosendf = X.iloc[:, etselected_index]\n",
    "\n",
    "et_train, et_test, y_train, y_test = train_test_split(chosendf, y, test_size=0.2, random_state=42)\n",
    "etc = ExtraTreesClassifier(n_estimators=100, random_state = 0)\n",
    "etc.fit(et_train, y_train)\n",
    "etc_predict = etc.predict(et_test)\n",
    "# accuracy.append(accuracy_score(y_test, rfc_predict))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, etc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[318, 378, 28, 128, 281, 105, 338, 475, 48, 153]\n",
      "[318, 378, 28, 442, 128, 281, 105, 338, 475, 48, 153]\n",
      "[318, 378, 105, 442, 128, 281, 28, 338, 475, 48, 153]\n",
      "[378, 442, 281]\n"
     ]
    }
   ],
   "source": [
    "print(dtselected_index)\n",
    "print(rfselected_index)\n",
    "print(etselected_index)\n",
    "print(selected_index_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
